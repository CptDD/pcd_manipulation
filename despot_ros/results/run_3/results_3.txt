Model = N6despot6POMDPXE
Random root seed = 755661000
Search depth = 10
Discount = 0.95
Simulation steps = 10
Number of scenarios = 500
Search time per step = 1
Regularization constant = 0
Lower bound = DEFAULT
Upper bound = DEFAULT
Policy simulation depth = 90
Target gap ratio = 0.95

####################################### Round 0 #######################################
-----------------------------------Round 0 Step 0-----------------------------------
- Action = 1:north
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.85
- Reward = -1
- Current rewards:
  discounted / undiscounted = -1 / -1
Pre
pdf for 4096 particles:
 [robot_1:vp2, state_1:elongated] = 0.5
 [robot_1:vp2, state_1:livarno] = 0.5

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 1-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 8.5 / 9
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 2-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 17.525 / 19
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 3-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 26.0987 / 29
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 4-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 34.2438 / 39
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 5-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:olivarno]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 41.9816 / 49
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 6-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 49.3325 / 59
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 7-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:olivarno]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 56.3159 / 69
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 8-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:oelongated]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 62.9501 / 79
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

-----------------------------------Round 0 Step 9-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp0, state_1:elongated]
- Observation = [obs_sensor:olivarno]
- ObsProb = 0.5
- Reward = 10
- Current rewards:
  discounted / undiscounted = 69.2526 / 89
Pre
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263

Post
pdf for 4096 particles:
 [robot_1:vp0, state_1:elongated] = 0.894737
 [robot_1:vp0, state_1:livarno] = 0.105263


Completed 1 run(s).
Average total discounted reward (stderr) = 69.2526 (0)
Average total undiscounted reward (stderr) = 89 (0)
Total time: Real / CPU = 16.5718 / 12.0252s
