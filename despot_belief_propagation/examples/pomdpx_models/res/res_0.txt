Model = N6despot6POMDPXE
Random root seed = 912077000
Search depth = 10
Discount = 0.95
Simulation steps = 10
Number of scenarios = 500
Search time per step = 1
Regularization constant = 0
Lower bound = DEFAULT
Upper bound = DEFAULT
Policy simulation depth = 90
Target gap ratio = 0.95

####################################### Round 0 #######################################
Initial state: [robot_1:vp15, state_1:livarno, state_3:elongated]

-----------------------------------Round 0 Step 0-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:oelongated, obs_sensor_2:olivarno]
- ObsProb = 0.01575
- Reward = -2
- Current rewards:
  discounted / undiscounted = -2 / -2

- Decomposed	0.5	0.5	0.5	0.5
Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.25

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.747314
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.148682
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.0876465
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.0163574

-----------------------------------Round 0 Step 1-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:olivarno, obs_sensor_2:oelongated]
- ObsProb = 0.25
Decision making!
- Decomposed	0.895996	0.104004	0.165039	0.834961
Counts :1024 1024 1024 1024
Joint :0.0825195 0.0825195 0.41748 0.41748
Norm factors :8.05855e-05 8.05855e-05 0.000407696 0.000407696
New first :1
New second :0
- Reward = -10
- Current rewards:
  discounted / undiscounted = -11.5 / -12

Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.41748
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.41748
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.0825195
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.0825195

Post
pdf for 4096 particles:
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.41748
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.41748
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.0825195
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.0825195

-----------------------------------Round 0 Step 2-----------------------------------
- Action = 5:d_livarno
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:oelongated, obs_sensor_2:olivarno]
- ObsProb = 0.25
Decision making!
- Decomposed	0.165039	0.834961	0.5	0.5
Counts :1024 1024 1024 1024
Joint :0.25 0.25 0.25 0.25
Norm factors :0.000244141 0.000244141 0.000244141 0.000244141
New first :0
New second :0
- Reward = 10
- Current rewards:
  discounted / undiscounted = -2.475 / -2

Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.25

Post
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.25

-----------------------------------Round 0 Step 3-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:elongated, state_3:elongated]
- Observation = [obs_sensor_1:oelongated, obs_sensor_2:oelongated]
- ObsProb = 0.772018
- Reward = -2
- Current rewards:
  discounted / undiscounted = -4.18975 / -4

- Decomposed	0.5	0.5	0.5	0.5
Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.25
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.25

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.692871
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.200928
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.0825195
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.0236816

-----------------------------------Round 0 Step 4-----------------------------------
- Action = 4:d_elongated
- State:[robot_1:vp16, state_1:elongated, state_3:elongated]
- Observation = [obs_sensor_1:olivarno, obs_sensor_2:olivarno]
- ObsProb = 0.25
Decision making!
- Decomposed	0.893799	0.106201	0.775391	0.224609
Counts :1024 1024 1024 1024
Joint :0.387695 0.387695 0.112305 0.112305
Norm factors :0.000378609 0.000378609 0.000109673 0.000109673
New first :1
New second :0
- Reward = 10
- Current rewards:
  discounted / undiscounted = 3.95531 / 6

Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.387695
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.387695
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.112305
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.112305

Post
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.387695
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.387695
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.112305
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.112305

-----------------------------------Round 0 Step 5-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:olivarno, obs_sensor_2:olivarno]
- ObsProb = 0.13425
- Reward = -2
- Current rewards:
  discounted / undiscounted = 2.40775 / 4

- Decomposed	0.775391	0.224609	0.5	0.5
Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.387695
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.387695
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.112305
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.112305

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.61552
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.217814
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.123104
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.0435627

-----------------------------------Round 0 Step 6-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:oelongated, obs_sensor_2:oelongated]
- ObsProb = 0.08925
- Reward = -2
- Current rewards:
  discounted / undiscounted = 0.937567 / 2

- Decomposed	0.261376	0.738624	0.166667	0.833333
Pre
pdf for 4096 particles:
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.61552
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.217814
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.123104
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.0435627

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.448664
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.305091
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.146574
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.0996706

-----------------------------------Round 0 Step 7-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:olivarno, obs_sensor_2:oelongated]
- ObsProb = 0.76075
- Reward = -2
- Current rewards:
  discounted / undiscounted = -0.459108 / 0

- Decomposed	0.753755	0.246245	0.404762	0.595238
Pre
pdf for 4096 particles:
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.448664
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.305091
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.146574
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.0996706

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.531346
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.229821
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.166721
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.0721112

-----------------------------------Round 0 Step 8-----------------------------------
- Action = 0:south
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:olivarno, obs_sensor_2:oelongated]
- ObsProb = 0.76075
- Reward = -2
- Current rewards:
  discounted / undiscounted = -1.78595 / -2

- Decomposed	0.238832	0.761168	0.698068	0.301932
Pre
pdf for 4096 particles:
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.531346
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.229821
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.166721
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.0721112

Post
pdf for 4096 particles:
 [robot_1:vp16, state_1:livarno, state_3:elongated] = 0.85791
 [robot_1:vp16, state_1:livarno, state_3:livarno] = 0.112061
 [robot_1:vp16, state_1:elongated, state_3:elongated] = 0.0275879
 [robot_1:vp16, state_1:elongated, state_3:livarno] = 0.00244141

-----------------------------------Round 0 Step 9-----------------------------------
- Action = 5:d_livarno
- State:[robot_1:vp16, state_1:livarno, state_3:elongated]
- Observation = [obs_sensor_1:oelongated, obs_sensor_2:oelongated]
- ObsProb = 0.25
Decision making!
- Decomposed	0.0300293	0.969971	0.885498	0.114502
Counts :1024 1024 1024 1024
Joint :0.442749 0.442749 0.057251 0.057251
Norm factors :0.000432372 0.000432372 5.59092e-05 5.59092e-05
New first :0
New second :0
- Reward = 10
- Current rewards:
  discounted / undiscounted = 4.51655 / 8

Pre
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.442749
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.442749
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.057251
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.057251

Post
pdf for 4096 particles:
 [robot_1:vp15, state_1:elongated, state_3:elongated] = 0.442749
 [robot_1:vp15, state_1:elongated, state_3:livarno] = 0.442749
 [robot_1:vp15, state_1:livarno, state_3:elongated] = 0.057251
 [robot_1:vp15, state_1:livarno, state_3:livarno] = 0.057251

Simulation terminated in 10 steps
Total discounted reward = 4.51655
Total undiscounted reward = 8

Completed 1 run(s).
Average total discounted reward (stderr) = 4.51655 (0)
Average total undiscounted reward (stderr) = 8 (0)
Total time: Real / CPU = 12.0538 / 11.8113s
